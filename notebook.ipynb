{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import dataloader, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "\n",
    "from torchmetrics import Recall, Precision, Accuracy, AUROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Resize((64, 64)),\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Resize((64, 64))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = ImageFolder(\n",
    "    'data/Combined dataset/train', \n",
    "    transform=train_transform\n",
    ")\n",
    "\n",
    "\n",
    "dataset_test = ImageFolder(\n",
    "    'data/Combined dataset/test', \n",
    "    transform=test_transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_train =  DataLoader(dataset_train, \n",
    "                               batch_size = 32, \n",
    "                               shuffle= True\n",
    "                               )\n",
    "\n",
    "dataloader_test = DataLoader(dataset_test, \n",
    "                             batch_size= 32, \n",
    "                             shuffle = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "images, labels = next(iter(dataloader_train))\n",
    "print(images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image = images[0]\n",
    "# image = image.squeeze().permute(1, 2, 0)\n",
    "\n",
    "# plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module): \n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=2, padding=1), \n",
    "            nn.ELU(), \n",
    "            nn.MaxPool2d(kernel_size=2), \n",
    "            nn.Conv2d(32, 64, kernel_size= 2, padding= 1), \n",
    "            nn.ELU(), \n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        self.classifier = nn.Linear(64 * 16*16, num_classes)\n",
    "\n",
    "\n",
    "    def forward (self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        x = self.classifier(x)\n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(num_classes= 4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr  = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_recall = Recall(task='multiclass', num_classes=4, average='macro')\n",
    "metric_precision = Precision(task='multiclass', num_classes=4, average='macro')\n",
    "metric_accuracy = Accuracy(task='multiclass', num_classes=4, average='macro')\n",
    "metric_auroc = AUROC(task='multiclass', num_classes=4, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range (10): \n",
    "    net.train()\n",
    "    for images, labels in dataloader_train:\n",
    "        optimizer.zero_grad()\n",
    "        output = net(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader_test:\n",
    "            output = net(images)\n",
    "            _, pred = torch.max(output, 1)\n",
    "            metric_accuracy(pred, labels)\n",
    "            metric_recall(pred, labels)\n",
    "            metric_precision(pred, labels)\n",
    "            # metric_auroc(pred, labels)\n",
    "    precision = metric_precision.compute()\n",
    "    recall = metric_recall.compute()\n",
    "    accuracy = metric_accuracy.compute()\n",
    "    # auroc = metric_auroc.compute()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision : 0.8552390933036804\n",
      "Recall: 0.861237645149231\n",
      "Accuracy : 0.861237645149231\n"
     ]
    }
   ],
   "source": [
    "print(f'Precision : {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'Accuracy : {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
